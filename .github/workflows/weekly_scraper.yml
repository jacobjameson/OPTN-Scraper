name: Weekly Data Scraper

on:
  schedule:
    - cron: '0 0 * * 0'  # Runs at 00:00 UTC every Sunday
  workflow_dispatch:  # Allows manual triggering

jobs:
  scrape:
    runs-on: macos-latest  # Using macOS runner for Safari WebDriver
    strategy:
      matrix:
        donor_type: [
          'All Donors by Donor Type',
          'Deceased Donors by Donor Age',
          'Deceased Donors by Donor Ethnicity',
          'Deceased Donors by Donor Gender',
          'Deceased Donors by Circumstance of Death',
          'Deceased Donors by Mechanism of Death',
          'Deceased Donors by Cause of Death',
          'Deceased Donors by DSA',
          'Living Donors by Donor Age',
          'Living Donors by Donor Ethnicity',
          'Living Donors by Donor Gender'
        ]
    steps:
    - uses: actions/checkout@v2
    
    - name: Set up Python
      uses: actions/setup-python@v2
      with:
        python-version: '3.x'
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
    
    - name: Run scraper for ${{ matrix.donor_type }}
      run: python scraper.py "${{ matrix.donor_type }}"
    
    - name: Commit and push if changes
      run: |
        git config --global user.name 'GitHub Action'
        git config --global user.email 'action@github.com'
        git add -A
        git diff --quiet && git diff --staged --quiet || (
          git pull --rebase
          git commit -m "Update data for ${{ matrix.donor_type }} $(date +'%Y-%m-%d')"
          git push https://${{ secrets.PAT }}@github.com/${{ github.repository }}.git
        )
